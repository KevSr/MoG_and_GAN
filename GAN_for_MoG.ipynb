{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVPeGfVUwbQM",
        "outputId": "611b3ad9-b890-48fb-f834-f458b8631e65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-rc1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/cf/2fc69ba3e59edc8333e2676fa71b40197718dea7dc1282c79955cf6b2acb/tensorflow_gpu-2.0.0rc1-cp36-cp36m-manylinux2010_x86_64.whl (380.5MB)\n",
            "\u001b[K     |████████████                    | 142.5MB 1.8MB/s eta 0:02:15"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziQshBSOwvhI",
        "outputId": "43bf42ba-0b80-45f3-841b-da67d91f4781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        }
      },
      "source": [
        "!pip install --upgrade tensorflow-gpu\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/bf/c28971266ca854a64f4b26f07c4112ddd61f30b4d1f18108b954a746f8ea/tensorflow_gpu-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2MB 31kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.2.2)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.3.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.2.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.29.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu) (47.3.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.6.0.post3)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (2020.4.5.2)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (4.1.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (1.6.1)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow-gpu) (3.1.0)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.2.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0KR6yckwcvY",
        "outputId": "79f4fd2b-db99-4a33-e8e5-7c28b9e2dc25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkMkvDjavUtf"
      },
      "source": [
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers\n",
        "import time\n",
        "from google.colab import drive\n",
        "\n",
        "from IPython import display\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x55IMQP5ZGY",
        "outputId": "c7cce184-bad1-4a1f-c92e-330170201188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CWTS2jTyLqY",
        "outputId": "989eeaf9-407a-4542-bc95-5423c15d621e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f = np.load('/content/drive/My Drive/Colab Notebooks/MMISEL_GB_train.npy')\n",
        "print(f.shape)\n",
        "train_images = np.array([])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIfwx3LR3syF",
        "outputId": "47e98e9d-a2c7-4d7b-d639-53cd87d75076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for i in range(f.shape[0]):\n",
        "    dist = f[i,:,:]\n",
        "    dist = dist.flatten()\n",
        "    if train_images.size == 0:\n",
        "      train_images = dist\n",
        "    else:\n",
        "      train_images = np.vstack((train_images,dist))\n",
        "print(train_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLp1VnrdvW7w",
        "outputId": "b6f276ad-57ab-4dca-bb6e-8297c1551b09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_images = train_images.reshape(train_images.shape[0], 784, 1).astype('float32')\n",
        "# train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "print(np.amax(train_images))\n",
        "train_images = (train_images - 127.5) / 127.5 # 이미지를 [-1, 1]로 정규화합니다.\n",
        "print(np.amax(train_images))\n",
        "BUFFER_SIZE = len(train_images)\n",
        "BATCH_SIZE = 500\n",
        "\n",
        "# 데이터 배치를 만들고 섞습니다.\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "EPOCHS = 30\n",
        "noise_dim = 100\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "254.94388\n",
            "0.9995598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pW1_L-lvaYu"
      },
      "source": [
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) # 주목: 배치사이즈로 None이 주어집니다.\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZzv1UkeyxfS"
      },
      "source": [
        "def make_1d_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(64*784, use_bias=False, input_dim=100))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((784, 64)))\n",
        "    assert model.output_shape == (None, 784, 64) # 주목: 배치사이즈로 None이 주어집니다.\n",
        "\n",
        "    model.add(layers.Conv1D(32, 5, padding = 'same', use_bias = False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv1D(16, 5, strides = 1, padding = 'same', use_bias = False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv1D(1, 5, strides = 1, padding = 'same', use_bias = False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 784, 1)\n",
        "  \n",
        "    # model.add(layers.Dense(256, use_bias = False, input_dim = 100, kernel_initializer = tf.keras.initializers.RandomNormal(stddev=0.02)))\n",
        "    # model.add(layers.LeakyReLU())\n",
        "\n",
        "    # model.add(layers.Dense(512, use_bias = False))\n",
        "    # model.add(layers.LeakyReLU())\n",
        "\n",
        "    # model.add(layers.Dense(1024, use_bias = False))\n",
        "    # model.add(layers.LeakyReLU())\n",
        "\n",
        "    # model.add(layers.Dense(2048, use_bias = False))\n",
        "    # model.add(layers.LeakyReLU())\n",
        "\n",
        "    # model.add(layers.Dense(784, use_bias = False, activation = 'tanh'))\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiSQkI0vveCz"
      },
      "source": [
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsks_GPhc4S7"
      },
      "source": [
        "def make_1d_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv1D(64, 5, strides = 2, padding = 'same', input_shape = [784,1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv1D(128, 5, strides = 2, padding = 'same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    # model.add(Dense(1024, input_dim = 784, kernel_initializer = tf.keras.initializers.RandomNormal(stddev=0.02)))\n",
        "    # model.add(layers.LeakyReLU())\n",
        "    # model.add(layers.Dropout(0.3))\n",
        "\n",
        "    # model.add(layers.Dense(512))\n",
        "    # model.add(layers.LeakyReLU())\n",
        "    # model.add(layers.Dropout(0.3))\n",
        "\n",
        "    # model.add(layers.Dense(256))\n",
        "    # model.add(layers.LeakyReLU())\n",
        "    # model.add(layers.Dropout(0.3))\n",
        "\n",
        "    # model.add(layers.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJvVKkoHvekg"
      },
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czbr1BvLvjTL",
        "outputId": "38442932-6625-419f-c897-cd2264cc998b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()\n",
        "\n",
        "generator_1d = make_1d_generator_model()\n",
        "discriminator_1d = make_1d_discriminator_model()\n",
        "generator_1d.summary()\n",
        "discriminator_1d.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 50176)             5017600   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 50176)             200704    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 50176)             0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 784, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 784, 32)           10240     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 784, 32)           128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 784, 32)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 784, 16)           2560      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 784, 16)           64        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 784, 16)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 784, 1)            80        \n",
            "=================================================================\n",
            "Total params: 5,231,376\n",
            "Trainable params: 5,130,928\n",
            "Non-trainable params: 100,448\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_3 (Conv1D)            (None, 392, 64)           384       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 392, 64)           0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 392, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_4 (Conv1D)            (None, 196, 128)          41088     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 196, 128)          0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 196, 128)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 25089     \n",
            "=================================================================\n",
            "Total params: 66,561\n",
            "Trainable params: 66,561\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_52gW7PeEI4Z"
      },
      "source": [
        "checkpoint_dir = '/content/drive/My Drive/Colab Notebooks/MMISEL_GB_ckpt'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)\n",
        "\n",
        "gene_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
        "discr_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
        "\n",
        "train_log_dir = '/content/drive/My Drive/Colab Notebooks/logs/train/'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUeVth__vmIp",
        "outputId": "2f856fe2-7e11-48f2-a6af-1242526049d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.uniform([BATCH_SIZE, noise_dim], seed = 1)\n",
        "    print(tf.shape(images))\n",
        "    print(images.shape)\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "        print(gen_loss, disc_loss)\n",
        "        gene_loss(gen_loss)\n",
        "        discr_loss(disc_loss)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dc713d3fd739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyLiqs3c2AcG"
      },
      "source": [
        "@tf.function\n",
        "def train_step_1d(images):\n",
        "    noise = tf.random.uniform([BATCH_SIZE, noise_dim], seed = 1)\n",
        "    print(tf.shape(images))\n",
        "    print(images.shape)\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator_1d(noise, training=True)\n",
        "\n",
        "        real_output = discriminator_1d(images, training=True)\n",
        "        fake_output = discriminator_1d(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "        print('a', gen_loss, disc_loss)\n",
        "        gene_loss(gen_loss)\n",
        "        discr_loss(disc_loss)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator_1d.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator_1d.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator_1d.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator_1d.trainable_variables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HICIV7Ai_riN"
      },
      "source": [
        "g_loss_t = []\n",
        "d_loss_t = []\n",
        "g_loss_v = []\n",
        "d_loss_v = []\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9suZR46voSO"
      },
      "source": [
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        batch_no = 0\n",
        "        for image_batch in dataset:\n",
        "            train_step(image_batch)\n",
        "            batch_no += 1\n",
        "            if batch_no % 5 == 0:\n",
        "              print(gene_loss.result().numpy(), discr_loss.result().numpy())\n",
        "              g_loss_t.append(gene_loss.result().numpy()) \n",
        "              d_loss_t.append(discr_loss.result().numpy())\n",
        "        \n",
        "\n",
        "        # GIF를 위한 이미지를 바로 생성합니다.\n",
        "        display.clear_output(wait=True)\n",
        "        generate_and_save_images(generator, epoch + 1,  seed)\n",
        "        with train_summary_writer.as_default():\n",
        "            tf.summary.scalar('gen_loss', gene_loss.result(), step=epoch) \n",
        "            tf.summary.scalar('disc_loss', discr_loss.result(), step=epoch)\n",
        "        \n",
        "        # 15 에포크가 지날 때마다 모델을 저장합니다.\n",
        "        if (epoch + 1) % 15 == 0:\n",
        "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    \n",
        "        # print (' 에포크 {} 에서 걸린 시간은 {} 초 입니다'.format(epoch +1, time.time()-start))\n",
        "        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "    \n",
        "        template = 'Epoch {}, gen_loss: {}, disc_loss: {}'\n",
        "        print(template.format(epoch+1, gene_loss.result(), discr_loss.result()))\n",
        "        \n",
        "\n",
        "        # Reset metrics every epoch\n",
        "        gene_loss.reset_states()\n",
        "        discr_loss.reset_states()\n",
        "    # 마지막 에포크가 끝난 후 생성합니다.\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator, epochs, seed)\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    plt.title('Change in cross-entropy loss during training for MMISEL_GB')\n",
        "    plt.plot(np.arange(len(g_loss_t)),g_loss_t, label = 'generator')\n",
        "    plt.plot(np.arange(len(d_loss_t)),d_loss_t, label = 'discriminator')\n",
        "    plt.legend()\n",
        "    plt.savefig('/content/drive/My Drive/Colab Notebooks/Train_graph_MMISEL_GB.png')\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyV5DHRS3Hr0"
      },
      "source": [
        "def train_1d(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        batch_no = 0\n",
        "        for image_batch in dataset:\n",
        "            train_step_1d(image_batch)\n",
        "            batch_no += 1\n",
        "            if batch_no % 5 == 0:\n",
        "              print(gene_loss.result().numpy(), discr_loss.result().numpy())\n",
        "              g_loss_t.append(gene_loss.result().numpy()) \n",
        "              d_loss_t.append(discr_loss.result().numpy())\n",
        "        \n",
        "\n",
        "        # GIF를 위한 이미지를 바로 생성합니다.\n",
        "        display.clear_output(wait=True)\n",
        "        generate_1d_images(generator_1d, epoch + 1)\n",
        "        with train_summary_writer.as_default():\n",
        "            tf.summary.scalar('gen_loss', gene_loss.result(), step=epoch) \n",
        "            tf.summary.scalar('disc_loss', discr_loss.result(), step=epoch)\n",
        "        \n",
        "        # 15 에포크가 지날 때마다 모델을 저장합니다.\n",
        "        if (epoch + 1) % 15 == 0:\n",
        "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    \n",
        "        # print (' 에포크 {} 에서 걸린 시간은 {} 초 입니다'.format(epoch +1, time.time()-start))\n",
        "        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "    \n",
        "        template = 'Epoch {}, gen_loss: {}, disc_loss: {}'\n",
        "        print(template.format(epoch+1, gene_loss.result(), discr_loss.result()))\n",
        "        \n",
        "\n",
        "        # Reset metrics every epoch\n",
        "        gene_loss.reset_states()\n",
        "        discr_loss.reset_states()\n",
        "    # 마지막 에포크가 끝난 후 생성합니다.\n",
        "    display.clear_output(wait=True)\n",
        "    generate_1d_images(generator_1d, epochs)\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    plt.title('Change in cross-entropy loss during training for MMISEL_GB')\n",
        "    plt.plot(np.arange(len(g_loss_t)),g_loss_t, label = 'generator')\n",
        "    plt.plot(np.arange(len(d_loss_t)),d_loss_t, label = 'discriminator')\n",
        "    plt.legend()\n",
        "    plt.savefig('/content/drive/My Drive/Colab Notebooks/Train_graph_MMISEL_GB.png')\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuaxPMxkvq8q"
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "# `training`이 False로 맞춰진 것을 주목하세요.\n",
        "# 이렇게 하면 (배치정규화를 포함하여) 모든 층들이 추론 모드로 실행됩니다. \n",
        "    predictions = model(test_input, training=False)\n",
        "\n",
        "    fig = plt.figure(figsize=(4,4))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig('/content/drive/My Drive/Colab Notebooks/images/MMISEL_GB_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2ZwP9X_2Jjs"
      },
      "source": [
        "def generate_1d_images(model, epoch):\n",
        "    noise = tf.random.uniform([4, noise_dim], seed = 1)\n",
        "    predictions = model(noise, training=False)\n",
        "\n",
        "    fig = plt.figure()\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(2, 2, i+1)\n",
        "        plt.hist(predictions[i,:,0] * 127.5 + 127.5, bins = 128)\n",
        "        plt.axis('on')\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQwKPnEMvvi6",
        "outputId": "6414b875-345f-46a6-c065-8e89e7982e26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "%%time\n",
        "train_1d(train_dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
            "(500, 784, 1)\n",
            "a Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32) Tensor(\"add:0\", shape=(), dtype=float32)\n",
            "0.95815784 1.3399599\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-425dd66f8ba8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_1d(train_dataset, EPOCHS)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-ede466769ab0>\u001b[0m in \u001b[0;36mtrain_1d\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbatch_no\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mtrain_step_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mbatch_no\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_no\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yB5wubLCGTB"
      },
      "source": [
        "def valid(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        batch_no = 0\n",
        "        checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "        for image_batch in dataset:\n",
        "            valid_step(image_batch)\n",
        "            batch_no += 1\n",
        "            if batch_no % 5 == 0:\n",
        "              print(gene_loss.result().numpy(), discr_loss.result().numpy())\n",
        "              g_loss_v.append(gene_loss.result().numpy()) \n",
        "              d_loss_v.append(discr_loss.result().numpy())\n",
        "\n",
        "\n",
        "        # GIF를 위한 이미지를 바로 생성합니다.\n",
        "        display.clear_output(wait=True)\n",
        "        with train_summary_writer.as_default():\n",
        "            tf.summary.scalar('gen_loss', gene_loss.result(), step=epoch) \n",
        "            tf.summary.scalar('disc_loss', discr_loss.result(), step=epoch)\n",
        "        \n",
        "    \n",
        "        # print (' 에포크 {} 에서 걸린 시간은 {} 초 입니다'.format(epoch +1, time.time()-start))\n",
        "        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "    \n",
        "        template = 'Epoch {}, gen_loss: {}, disc_loss: {}'\n",
        "        print(template.format(epoch+1, gene_loss.result(), discr_loss.result()))\n",
        "\n",
        "        # Reset metrics every epoch\n",
        "        gene_loss.reset_states()\n",
        "        discr_loss.reset_states()\n",
        "    # 마지막 에포크가 끝난 후 생성합니다.\n",
        "    plt.title('Change in cross-entropy loss during validation for MMISEL_GB')\n",
        "    plt.plot(np.arange(len(g_loss_v)),g_loss_v, label = 'generator')\n",
        "    plt.plot(np.arange(len(d_loss_v)),d_loss_v, label = 'discriminator')\n",
        "    plt.legend()\n",
        "    plt.savefig('/content/drive/My Drive/Colab Notebooks/valid_graph_MMISEL_GB.png')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHCJyddP_hR8"
      },
      "source": [
        "def valid_1d(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        batch_no = 0\n",
        "        checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "        for image_batch in dataset:\n",
        "            valid_step_1d(image_batch)\n",
        "            batch_no += 1\n",
        "            if batch_no % 5 == 0:\n",
        "              print(gene_loss.result().numpy(), discr_loss.result().numpy())\n",
        "              g_loss_v.append(gene_loss.result().numpy()) \n",
        "              d_loss_v.append(discr_loss.result().numpy())\n",
        "\n",
        "\n",
        "        # GIF를 위한 이미지를 바로 생성합니다.\n",
        "        display.clear_output(wait=True)\n",
        "        with train_summary_writer.as_default():\n",
        "            tf.summary.scalar('gen_loss', gene_loss.result(), step=epoch) \n",
        "            tf.summary.scalar('disc_loss', discr_loss.result(), step=epoch)\n",
        "        \n",
        "    \n",
        "        # print (' 에포크 {} 에서 걸린 시간은 {} 초 입니다'.format(epoch +1, time.time()-start))\n",
        "        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "    \n",
        "        template = 'Epoch {}, gen_loss: {}, disc_loss: {}'\n",
        "        print(template.format(epoch+1, gene_loss.result(), discr_loss.result()))\n",
        "\n",
        "        # Reset metrics every epoch\n",
        "        gene_loss.reset_states()\n",
        "        discr_loss.reset_states()\n",
        "    # 마지막 에포크가 끝난 후 생성합니다.\n",
        "    plt.title('Change in cross-entropy loss during validation for MMISEL_GB')\n",
        "    plt.plot(np.arange(len(g_loss_v)),g_loss_v, label = 'generator')\n",
        "    plt.plot(np.arange(len(d_loss_v)),d_loss_v, label = 'discriminator')\n",
        "    plt.legend()\n",
        "    plt.savefig('/content/drive/My Drive/Colab Notebooks/valid_graph_MMISEL_GB.png')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0-MV8qZFu2c"
      },
      "source": [
        "v = np.load('/content/drive/My Drive/Colab Notebooks/MMISEL_GB_valid.npy')\n",
        "valid_images = np.array([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mjWiU0r_pRW"
      },
      "source": [
        "for i in range(v.shape[0]):\n",
        "    dist = v[i,:,:]\n",
        "    dist = dist.flatten()\n",
        "    if valid_images.size == 0:\n",
        "      valid_images = dist\n",
        "    else:\n",
        "      valid_images = np.vstack((valid_images,dist))\n",
        "print(valid_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "800OHjnN_olY"
      },
      "source": [
        "valid_images = valid_images.reshape(valid_images.shape[0], 784,1).astype('float32')\n",
        "# valid_images = valid_images.reshape(valid_images.shape[0], 28, 28, 1).astype('float32')\n",
        "valid_images = (valid_images - 127.5) / 127.5 # 이미지를 [-1, 1]로 정규화합니다.\n",
        "BUFFER_SIZE = len(valid_images)\n",
        "BATCH_SIZE = 500\n",
        "\n",
        "# 데이터 배치를 만들고 섞습니다.\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices(valid_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "EPOCHS = 30\n",
        "noise_dim = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVQAD0eRBw-4"
      },
      "source": [
        "@tf.function\n",
        "def valid_step(images):\n",
        "    noise = tf.random.uniform([BATCH_SIZE, noise_dim], seed = 1)\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=False)\n",
        "        real_output = discriminator(images, training=False)\n",
        "        fake_output = discriminator(generated_images, training=False)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        gene_loss(gen_loss)\n",
        "        discr_loss(disc_loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rEkza8o_9eZ"
      },
      "source": [
        "@tf.function\n",
        "def valid_step_1d(images):\n",
        "    noise = tf.random.uniform([BATCH_SIZE, noise_dim], seed = 1)\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator_1d(noise, training=False)\n",
        "        real_output = discriminator_1d(images, training=False)\n",
        "        fake_output = discriminator_1d(generated_images, training=False)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        gene_loss(gen_loss)\n",
        "        discr_loss(disc_loss)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z1pZN_yFioc"
      },
      "source": [
        "%%time\n",
        "valid_1d(valid_dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u-oyejRUTWT"
      },
      "source": [
        "loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
        "ms = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8TgHMmsgY5T"
      },
      "source": [
        "@tf.function\n",
        "def test_step(images):\n",
        "    noise = tf.random.uniform([BATCH_SIZE, noise_dim], seed = 1)\n",
        "    generated_images = generator(noise, training=False)\n",
        "    print(images, generated_images)\n",
        "    mse = tf.keras.losses.MSE(generated_images, images)\n",
        "    loss(mse)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbpQi9kgB6ff"
      },
      "source": [
        "@tf.function\n",
        "def test_step_1d(images):\n",
        "    noise = tf.random.uniform([BATCH_SIZE, noise_dim], seed = 1)\n",
        "    generated_images = generator_1d(noise, training=False)\n",
        "    print(images, generated_images)\n",
        "    mse = tf.keras.losses.MSE(generated_images, images)\n",
        "    loss(mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g3lHIUSgniA"
      },
      "source": [
        "def test(dataset, epochs):\n",
        "    sum_mse = 0\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        batch_no = 0\n",
        "        checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "        i=0\n",
        "        for image_batch in dataset:\n",
        "            test_step(image_batch)\n",
        "            # print(loss.result().numpy())\n",
        "            ms.append(loss.result().numpy())\n",
        "        \n",
        "        # print (' 에포크 {} 에서 걸린 시간은 {} 초 입니다'.format(epoch +1, time.time()-start))\n",
        "        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "    \n",
        "\n",
        "\n",
        "    # 마지막 에포크가 끝난 후 생성합니다.\n",
        "    for i in range(len(ms)):\n",
        "      sum_mse += ms[i]\n",
        "    print(sum_mse/len(ms))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6ObRO5dB9wb"
      },
      "source": [
        "def test_1d(dataset, epochs):\n",
        "    sum_mse = 0\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        batch_no = 0\n",
        "        checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "        i=0\n",
        "        for image_batch in dataset:\n",
        "            test_step_1d(image_batch)\n",
        "            # print(loss.result().numpy())\n",
        "            ms.append(loss.result().numpy())\n",
        "        \n",
        "        # print (' 에포크 {} 에서 걸린 시간은 {} 초 입니다'.format(epoch +1, time.time()-start))\n",
        "        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "    \n",
        "\n",
        "\n",
        "    # 마지막 에포크가 끝난 후 생성합니다.\n",
        "    for i in range(len(ms)):\n",
        "      sum_mse += ms[i]\n",
        "    print(sum_mse/len(ms))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8I-iFPcbaUqc"
      },
      "source": [
        "t = np.load('/content/drive/My Drive/Colab Notebooks/MMISEL_GB_test.npy')\n",
        "test_images = np.array([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-oXckTRCAxK"
      },
      "source": [
        "for i in range(t.shape[0]):\n",
        "    dist = t[i,:,:]\n",
        "    dist = dist.flatten()\n",
        "    if test_images.size == 0:\n",
        "      test_images = dist\n",
        "    else:\n",
        "      test_images = np.vstack((test_images,dist))\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOMIMbNwCCCg"
      },
      "source": [
        "test_images = test_images.reshape(test_images.shape[0], 784, 1).astype('float32')\n",
        "# test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')\n",
        "test_images = (test_images - 127.5) / 127.5 # 이미지를 [-1, 1]로 정규화합니다.\n",
        "BUFFER_SIZE = len(test_images)\n",
        "BATCH_SIZE = 50\n",
        "\n",
        "# 데이터 배치를 만들고 섞습니다.\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(test_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "EPOCHS = 10\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX9vmy2ig2qk"
      },
      "source": [
        "%%time\n",
        "test_1d(test_dataset,EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}